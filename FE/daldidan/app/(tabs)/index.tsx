import { Canvas, Group, Rect } from '@shopify/react-native-skia';
import React, { useEffect, useRef, useState } from 'react';
import { Alert, StyleSheet, Text, View } from 'react-native';
import {
  loadTensorflowModel,
  TensorflowModel,
  TensorflowModelDelegate,
} from 'react-native-fast-tflite';
import {
  Camera,
  useCameraDevice,
  useFrameProcessor,
} from 'react-native-vision-camera';
import { Worklets } from 'react-native-worklets-core';
import { useResizePlugin } from 'vision-camera-resize-plugin';

// ğŸ”¥ COCO í´ë˜ìŠ¤ ì´ë¦„ ë°°ì—´ ì¶”ê°€
const COCO_CLASS_NAMES = [
  'person',
  'bicycle',
  'car',
  'motorcycle',
  'airplane',
  'bus',
  'train',
  'truck',
  'boat',
  'traffic light',
  'fire hydrant',
  'stop sign',
  'parking meter',
  'bench',
  'bird',
  'cat',
  'dog',
  'horse',
  'sheep',
  'cow',
  'elephant',
  'bear',
  'zebra',
  'giraffe',
  'backpack',
  'umbrella',
  'handbag',
  'tie',
  'suitcase',
  'frisbee',
  'skis',
  'snowboard',
  'sports ball',
  'kite',
  'baseball bat',
  'baseball glove',
  'skateboard',
  'surfboard',
  'tennis racket',
  'bottle',
  'wine glass',
  'cup',
  'fork',
  'knife',
  'spoon',
  'bowl',
  'banana',
  'apple',
  'sandwich',
  'orange',
  'broccoli',
  'carrot',
  'hot dog',
  'pizza',
  'donut',
  'cake',
  'chair',
  'couch',
  'potted plant',
  'bed',
  'dining table',
  'toilet',
  'TV',
  'laptop',
  'mouse',
  'remote',
  'keyboard',
  'cell phone',
  'microwave',
  'oven',
  'toaster',
  'sink',
  'refrigerator',
  'book',
  'clock',
  'vase',
  'scissors',
  'teddy bear',
  'hair drier',
  'toothbrush',
];

// ëª¨ë¸ ì„¤ì •
const MODEL_INPUT_SIZE = 320;
const CONFIDENCE_THRESHOLD = 0.3;

interface Detection {
  x: number;
  y: number;
  width: number;
  height: number;
  score?: number;
  class_id?: number;
}

export default function App() {
  const device = useCameraDevice('back');
  const [hasPermission, setHasPermission] = useState(false);
  const modelRef = useRef<TensorflowModel | null>(null);
  const frameCount = Worklets.createSharedValue(0);
  const { resize } = useResizePlugin();
  const [detections, setDetections] = useState<Detection[]>([]);
  const [screenSize, setScreenSize] = useState({ width: 0, height: 0 });

  // ì…ë ¥ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€
  const preprocessFrame = (frame, targetSize) => {
    'worklet';
    // EfficientDet ëª¨ë¸ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ì „ì²˜ë¦¬
    // ë©”íƒ€ë°ì´í„°: quantization: linear 0.0078125 * (q - 127)
    return resize(frame, {
      scale: { width: targetSize, height: targetSize },
      pixelFormat: 'rgb',
      dataType: 'uint8',
      normalization: {
        mean: [127, 127, 127], // zero point = 127
        std: [128, 128, 128], // 1/0.0078125 = 128
      },
    });
  };

  // 60fps í¬ë§· ì°¾ê¸°
  const format =
    device?.formats.find((f) => f.maxFps >= 60) ?? device?.formats[0];
  const fps = format ? Math.min(60, format.maxFps) : 30;

  // ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜
  const updateDetections = (data: Detection[]) => {
    setDetections(data);
  };

  // Worklet í•¨ìˆ˜ ìƒì„±
  const updateDetectionsWorklet = Worklets.createRunOnJS(updateDetections);

  useEffect(() => {
    (async () => {
      const status = await Camera.requestCameraPermission();
      setHasPermission(status === 'granted');
    })();
  }, []);

  useEffect(() => {
    const loadModel = async () => {
      try {
        const model = await loadTensorflowModel(
          require('../../assets/model.tflite'),
          'gpu' as TensorflowModelDelegate
        );
        console.log('Model loaded successfully:', model);
        modelRef.current = model;
      } catch (error: any) {
        console.error('Model loading error:', error);
        Alert.alert('Model Error', error.message);
      }
    };
    loadModel();
  }, []);

  // frameProcessor í•¨ìˆ˜ ë‚´ë¶€ ìˆ˜ì •
  const frameProcessor = useFrameProcessor(
    (frame) => {
      'worklet';
      if (!modelRef.current) return;

      // í”„ë ˆì„ ì¹´ìš´í„° ì—…ë°ì´íŠ¸ (ì„±ëŠ¥ ìµœì í™”)
      frameCount.value = (frameCount.value + 1) % 1; // 10í”„ë ˆì„ë§ˆë‹¤ ì²˜ë¦¬ë¡œ ë³€ê²½
      if (frameCount.value !== 0) return;

      try {
        console.log('í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘');

        // ìµœì í™”ëœ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì‚¬ìš©
        const resized = preprocessFrame(frame, MODEL_INPUT_SIZE);
        console.log('ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ');

        const outputs = modelRef.current.runSync([resized]);
        console.log('ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ');

        // ì˜¬ë°”ë¥¸ ì¶œë ¥ í…ì„œ ìˆœì„œë¡œ ì ‘ê·¼ (EfficientDet ëª¨ë¸ ê¸°ì¤€)
        const boxes = outputs[0] as Float32Array; // ë°”ìš´ë”© ë°•ìŠ¤ (StatefulPartitionedCall:0)
        const classes = outputs[1] as Float32Array; // í´ë˜ìŠ¤ ID (StatefulPartitionedCall:1)
        const scores = outputs[2] as Float32Array; // ì‹ ë¢°ë„ ì ìˆ˜ (StatefulPartitionedCall:2)
        const numDetections = outputs[3] as Float32Array; // ê²€ì¶œ ìˆ˜ (StatefulPartitionedCall:3)

        // ì‹¤ì œ ê°ì§€ëœ ê°ì²´ ìˆ˜ ì‚¬ìš© (ìµœëŒ€ 25ê°œ)
        const totalDetections = Math.min(
          Math.round(numDetections[0] || 0), // ì‹¤ì œ ê°ì§€ëœ ê°ì²´ ìˆ˜ ë˜ëŠ” 0
          scores.length
        );

        console.log('ê°ì§€ëœ ê°ì²´ ìˆ˜:', totalDetections);

        const detected: Detection[] = [];

        for (let i = 0; i < totalDetections; i++) {
          // ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸
          if (scores[i] < CONFIDENCE_THRESHOLD) continue;

          // EfficientDet ì¶œë ¥ í˜•ì‹: [y1, x1, y2, x2] (ì •ê·œí™”ëœ ì¢Œí‘œ)
          const y1 = boxes[i * 4];
          const x1 = boxes[i * 4 + 1];
          const y2 = boxes[i * 4 + 2];
          const x2 = boxes[i * 4 + 3];

          // ìœ íš¨í•œ ì¢Œí‘œê°’ ê²€ì¦
          if ([x1, y1, x2, y2].some((v) => isNaN(v) || v < 0 || v > 1)) {
            console.log(`detection[${i}] ìœ íš¨í•˜ì§€ ì•Šì€ ì¢Œí‘œ, ê±´ë„ˆëœ€`);
            continue;
          }

          // í™”ë©´ í¬ê¸°ì— ë§ê²Œ ë³€í™˜ (ì¢Œí‘œ ìˆœì„œ ìˆ˜ì •)
          const x = Math.min(Math.max(x1 * frame.width, 0), frame.width);
          const y = Math.min(Math.max(y1 * frame.height, 0), frame.height);
          const width = Math.min((x2 - x1) * frame.width, frame.width - x);
          const height = Math.min((y2 - y1) * frame.height, frame.height - y);

          const classId = Math.round(classes[i]);
          const className =
            classId < COCO_CLASS_NAMES.length
              ? COCO_CLASS_NAMES[classId]
              : 'unknown';

          console.log(
            `ê°ì§€ëœ ê°ì²´[${i}]: ${className} (ì‹ ë¢°ë„: ${Math.round(
              scores[i] * 100
            )}%) ` +
              `ìœ„ì¹˜: x=${Math.round(x)}, y=${Math.round(y)}, w=${Math.round(
                width
              )}, h=${Math.round(height)}`
          );

          detected.push({
            x,
            y,
            width,
            height,
            score: scores[i],
            class_id: classId,
          });
        }

        console.log(`ì´ ${detected.length}ê°œì˜ ê°ì²´ ê°ì§€ ì™„ë£Œ`);
        updateDetectionsWorklet(detected);
      } catch (error) {
        console.error('ê°ì²´ ê°ì§€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error);
      }
    },
    [updateDetectionsWorklet]
  );
  if (!hasPermission || !device || !format) {
    return <View style={styles.container} />;
  }

  return (
    <View
      style={StyleSheet.absoluteFill}
      onLayout={(event) => {
        const { width, height } = event.nativeEvent.layout;
        setScreenSize({ width, height });
      }}
    >
      <Camera
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={true}
        frameProcessor={frameProcessor}
        fps={fps}
        format={format}
      />
      <Canvas style={StyleSheet.absoluteFill}>
        <Group>
          {detections.map((detection, i) => {
            // í™”ë©´ ë¹„ìœ¨ì— ë§ê²Œ ì¢Œí‘œ ì¡°ì •
            const scaleX = screenSize.width / (format?.videoWidth || 1);
            const scaleY = screenSize.height / (format?.videoHeight || 1);

            const x = detection.x * scaleX;
            const y = detection.y * scaleY;
            const width = detection.width * scaleX;
            const height = detection.height * scaleY;

            return (
              <Group key={i}>
                <Rect
                  x={x}
                  y={y}
                  width={width}
                  height={height}
                  color='red'
                  style='stroke'
                  strokeWidth={3}
                />
              </Group>
            );
          })}
        </Group>
      </Canvas>
      {detections.map((detection, i) => {
        // í™”ë©´ ë¹„ìœ¨ì— ë§ê²Œ ì¢Œí‘œ ì¡°ì •
        const scaleX = screenSize.width / (format?.videoWidth || 1);
        const scaleY = screenSize.height / (format?.videoHeight || 1);

        const x = detection.x * scaleX;
        const y = detection.y * scaleY;

        return (
          <View
            key={i}
            style={[
              styles.textContainer,
              {
                position: 'absolute',
                left: Math.max(0, Math.min(x, screenSize.width - 150)),
                top: Math.max(0, Math.min(y - 25, screenSize.height - 25)),
                width: 150,
              },
            ]}
          >
            <Text style={styles.text} numberOfLines={1}>
              {detection.class_id !== undefined &&
              detection.class_id < COCO_CLASS_NAMES.length
                ? COCO_CLASS_NAMES[detection.class_id]
                : 'unknown'}{' '}
              ({Math.round(detection.score! * 100)}%)
            </Text>
          </View>
        );
      })}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    backgroundColor: 'black',
  },
  textContainer: {
    backgroundColor: 'rgba(0, 0, 0, 0.5)',
    padding: 4,
    borderRadius: 4,
    zIndex: 1,
  },
  text: {
    color: 'white',
    fontSize: 12,
    fontWeight: 'bold',
  },
});
