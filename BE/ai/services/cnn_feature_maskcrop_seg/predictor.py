# import numpy as np
# import cv2
# import torch
# from PIL import Image
# from .model_loader import model, scaler, transform

# # .features.extract_featuresì—ì„œ ê°€ì ¸ì˜¤ëŠ” ëª¨ë¸ ìˆ˜ì •
# # from .features.extract_features import extract_fast_features
# from .features.extract_features import extract_features

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# def predict_bytes(image_bytes: bytes) -> float:
#     try:
#         np_arr = np.frombuffer(image_bytes, np.uint8)
#         img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

#         if img is None:
#             raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")

#         h, w = img.shape[:2]
#         mask = np.ones((h, w), dtype=np.uint8) * 255

#         # .features.extract_featuresì—ì„œ ê°€ì ¸ì˜¤ëŠ” ëª¨ë¸ ìˆ˜ì •
#         # manual_feat = extract_fast_features(img, mask)
#         manual_feat = extract_features(img, mask)

#         manual_feat = scaler.transform([manual_feat])[0]
#         manual_feat_tensor = torch.tensor(manual_feat, dtype=torch.float32).unsqueeze(0).to(device)
#         image_tensor = transform(img).unsqueeze(0).to(device)

#         with torch.no_grad():
#             pred = model(image_tensor, manual_feat_tensor).squeeze().item()

#         return round(pred, 2)

#     except Exception as e:
#         print(f"[ERROR] predict_bytes ì‹¤íŒ¨: {e}")
#         raise e


## í‘¸ë¥¸ ì‚¬ê³¼ ë³´ì •ì„ ìœ„í•´ predictì‹œë§Œ ì‚¬ìš©í• ê²ƒ. í•™ìŠµì‹œì—ëŠ” ì£¼ì„ì²˜ë¦¬ í• ê²ƒ(ì‹œì‘ì )
import numpy as np
import cv2
import torch
from PIL import Image
from .model_loader import model, scaler, transform
from .features.extract_features import extract_features  # ì‚¬ìš© í•¨ìˆ˜

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def predict_bytes(image_bytes: bytes) -> float:
    try:
        np_arr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

        if img is None:
            raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
        # print("ğŸ“¥ ì´ë¯¸ì§€ ë””ì½”ë”© ì™„ë£Œ")  # âœ… ì—¬ê¸°ê°€ ë””ì½”ë”© ì„±ê³µ ì§í›„

        h, w = img.shape[:2]
        mask = np.ones((h, w), dtype=np.uint8) * 255

        feats = extract_features(img, mask)  # <- ì¶”ë¡  ì‹œ ì‚¬ìš©
        # print("ğŸ“Š ì¶”ì¶œëœ feats:", feats)  # âœ… ì¶”ì¶œ ì™„ë£Œ ì§í›„

        a_mean = feats["a_mean"]
        b_mean = feats["b_mean"]
        delta_E = feats["delta_E"]
        # print(f"a: {a_mean:.2f}, b: {b_mean:.2f}, delta_E: {delta_E:.2f}")

        # if a_mean < 125 and b_mean > 110:
        #     if delta_E > 80:
        #         print("ğŸŸ¢ í‘¸ë¥¸ ì‚¬ê³¼ ê°ì§€ â†’ ë¸Œë¦­ìŠ¤ 7.5ë¡œ ì†Œí”„íŠ¸ ë³´ì •")
        #         return 7.5
        #     elif delta_E > 70:
        #         print("ğŸŸ¡ í‘¸ë¥¸ ê¸°ìƒ‰ ê°ì§€ â†’ ë¸Œë¦­ìŠ¤ 8.0ìœ¼ë¡œ ì†Œí”„íŠ¸ ë³´ì •")
        #         return 8.0
        if a_mean < 133 and b_mean > 130:
            if delta_E > 55:
                print("ğŸŸ¢ í‘¸ë¥¸ ì‚¬ê³¼ ê°ì§€ â†’ ë¸Œë¦­ìŠ¤ 7.5ë¡œ ì†Œí”„íŠ¸ ë³´ì •")
                return 7.5
            elif delta_E > 45:
                print("ğŸŸ¡ í‘¸ë¥¸ ê¸°ìƒ‰ ê°ì§€ â†’ ë¸Œë¦­ìŠ¤ 8.0ìœ¼ë¡œ ì†Œí”„íŠ¸ ë³´ì •")
                return 8.0

        # ğŸ¯ CNN ì¶”ë¡ 
        feat_vector = np.array(
            [feats[k] for k in list(feats)[:6]]
        )  # CNN í•™ìŠµ í”¼ì²˜ë§Œ ì¶”ì¶œ

        manual_feat = scaler.transform([feat_vector])[0]  # â— ì—¬ê¸°ê°€ ìˆ˜ì • í¬ì¸íŠ¸
        # print("âœ… CNN ì˜ˆì¸¡ ì „ manual_feat:", manual_feat)  # âœ… CNN ì…ë ¥ ì§ì „
        manual_feat_tensor = (
            torch.tensor(manual_feat, dtype=torch.float32).unsqueeze(0).to(device)
        )
        image_tensor = transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            pred = model(image_tensor, manual_feat_tensor).squeeze().item()

        return round(pred, 2)

    except Exception as e:
        print(f"[ERROR] predict_bytes ì‹¤íŒ¨: {e}")
        raise e
        ## í‘¸ë¥¸ ì‚¬ê³¼ ë³´ì •ì„ ìœ„í•´ predictì‹œë§Œ ì‚¬ìš©í• ê²ƒ. í•™ìŠµì‹œì—ëŠ” ì£¼ì„ì²˜ë¦¬ í• ê²ƒ(ëì )
