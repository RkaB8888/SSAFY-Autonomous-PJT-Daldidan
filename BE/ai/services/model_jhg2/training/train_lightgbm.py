# services/model_jhg2/training/train_lightgbm.py
import json
import joblib
from pathlib import Path
from typing import List, Tuple

import lightgbm as lgb
import numpy as np
from tqdm import tqdm
from sklearn.feature_selection import VarianceThreshold

from common_utils.image_cropper import crop_bbox_from_json
from services.model_jhg2.utils.cnn_feature_extractor import extract_batch
from services.model_jhg2.config import (
    IMAGES_DIR,
    JSONS_DIR,
    MODEL_SAVE_PATH,
    CACHE_DIR,
)
from services.model_jhg2.extract_embeddings import build_and_cache_embeddings


def _make_feature_names(dim: int) -> List[str]:
    return [f"cnn_{i}" for i in range(dim)]


def load_dataset(
    images_dir: Path, jsons_dir: Path
) -> Tuple[np.ndarray, np.ndarray, List[str]]:
    feat_cache = CACHE_DIR / "train_embeddings.npy"
    label_cache = CACHE_DIR / "train_labels.npy"

    # 1) ìºì‹œê°€ ì—†ìœ¼ë©´ extract_embeddings ë¡œì§ í•¨ìˆ˜ í˜¸ì¶œ
    if not (feat_cache.exists() and label_cache.exists()):
        print("ğŸš€ ìºì‹œê°€ ì—†ìœ¼ë¯€ë¡œ build_and_cache_embeddings() ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤â€¦")
        build_and_cache_embeddings(img_dir=images_dir, json_dir=jsons_dir)
        print("âœ… ì„ë² ë”© ìºì‹œ ìƒì„± ì™„ë£Œ.")

    # 2) ìºì‹œì—ì„œ ë°”ë¡œ ë¡œë“œ
    X = np.memmap(feat_cache, dtype=np.float32, mode="r").reshape(-1, 1280)
    y = np.memmap(label_cache, dtype=np.float32, mode="r", shape=(X.shape[0],))

    print(f"âœ… Loaded cached train set: {len(X)} samples")

    # feature_namesëŠ” CNN ì°¨ì›ì— ë§ì¶° ìƒì„±
    feature_names = _make_feature_names(X.shape[1])
    return X, y, feature_names


def train_lightgbm(
    X: np.ndarray, y: np.ndarray, feature_names: List[str], save_path: Path
):
    # â”€â”€â”€â”€â”€â”€â”€ ìƒìˆ˜ íŠ¹ì„± ì œê±° (CNN ë²¡í„°ë¼ ê±°ì˜ ë³€í™” ì—†ì§€ë§Œ ì•ˆì „ ì°¨ì›) â”€â”€â”€â”€â”€â”€â”€
    selector = VarianceThreshold(threshold=0.0)
    X_reduced = selector.fit_transform(X)

    # â”€â”€â”€â”€â”€â”€â”€ LightGBM ì„¤ì • â”€â”€â”€â”€â”€â”€â”€
    model = lgb.LGBMRegressor(
        n_estimators=500,  # ğŸ”„ ë°°ì¹˜ í•™ìŠµ ë¹ ë¥´ë¯€ë¡œ tree ìˆ˜â†‘
        learning_rate=0.05,
        max_depth=-1,  # ğŸ”„ CNN ë²¡í„°ëŠ” ë³µì¡í•´ depth ì œí•œ í•´ì œ
        device="gpu",
        gpu_use_dp=True,
        random_state=42,
    )
    model.fit(X_reduced, y)

    # -- ëª¨ë¸ + selector + ì›ë³¸ feature_names í•œêº¼ë²ˆì— ë¤í”„ --
    save_path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(
        {"model": model, "selector": selector, "feature_names": feature_names},
        save_path,
    )
    print(f"âœ… LightGBM + meta ì €ì¥ ì™„ë£Œ: {save_path}")


def main():
    X, y, feature_names = load_dataset(IMAGES_DIR, JSONS_DIR)
    print(f"â–¶ ë°ì´í„° í˜•íƒœ: {X.shape}, y ë¶„í¬ (min~max): {y.min():.1f}~{y.max():.1f}")
    train_lightgbm(X, y, feature_names, MODEL_SAVE_PATH)


if __name__ == "__main__":
    main()
